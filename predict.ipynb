{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "from scipy import signal\n",
    "import scipy.fftpack\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import random\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import VotingClassifier,RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `1. Importing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "walkSit = []\n",
    "walkFall = []\n",
    "runFall = []\n",
    "downSit = []\n",
    "freeFall = []\n",
    "runSit = []\n",
    "for i in range(3):\n",
    "    walkSit.append(pd.read_csv(\"Data/testData/walkSit{}.csv\".format(i+1), sep = ';'))\n",
    "\n",
    "for i in range(3):    \n",
    "    walkFall.append(pd.read_csv(\"Data/testData/walkFall{}.csv\".format(i+1), sep = ';'))\n",
    "\n",
    "for i in range(3):\n",
    "    runFall.append(pd.read_csv(\"Data/testData/runFall{}.csv\".format(i+1), sep = ';'))\n",
    "\n",
    "for i in range(3):\n",
    "    downSit.append(pd.read_csv(\"Data/testData/downSit{}.csv\".format(i+1), sep = ';'))\n",
    "\n",
    "for i in range(3):\n",
    "    freeFall.append(pd.read_csv(\"Data/testData/freeFall{}.csv\".format(i+1), sep = ';'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `2. Cleaning`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using low pass filter \n",
    "b, a = signal.butter(3, 0.1, btype='lowpass', analog=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# walksit\n",
    "low_passed_walkSit = []\n",
    "for i in range(3):\n",
    "    low_passed_walkSitX = list(signal.filtfilt(b, a, walkSit[i][\"AccelerationX\"]))\n",
    "    low_passed_walkSitY = list(signal.filtfilt(b, a, walkSit[i][\"AccelerationY\"]))\n",
    "    low_passed_walkSitZ = list(signal.filtfilt(b, a, walkSit[i][\"AccelerationZ\"]))\n",
    "    low_passed_walkSit.append((pd.DataFrame(list(zip(low_passed_walkSitX, low_passed_walkSitY, low_passed_walkSitZ)),\n",
    "                                            columns=[\"AccelerationX\", \"AccelerationY\", \"AccelerationZ\"])))\n",
    "for i in range(3):\n",
    "    low_passed_walkSit[i][\"AccelerationT\"] = np.sqrt(walkSit[i][\"AccelerationX\"]**2 * \n",
    "                                                     walkSit[i][\"AccelerationY\"]**2 *\n",
    "                                                     walkSit[i][\"AccelerationZ\"]**2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_passed_walkFall = []\n",
    "for i in range(3):\n",
    "    low_passed_walkFallX = list(signal.filtfilt(b, a, walkFall[i][\"AccelerationX\"]))\n",
    "    low_passed_walkFallY = list(signal.filtfilt(b, a, walkFall[i][\"AccelerationY\"]))\n",
    "    low_passed_walkFallZ = list(signal.filtfilt(b, a, walkFall[i][\"AccelerationZ\"]))\n",
    "    low_passed_walkFall.append((pd.DataFrame(list(zip(low_passed_walkFallX, low_passed_walkFallY, low_passed_walkFallZ)),\n",
    "                                            columns=[\"AccelerationX\", \"AccelerationY\", \"AccelerationZ\"])))\n",
    "\n",
    "for i in range(3):\n",
    "    low_passed_walkFall[i][\"AccelerationT\"] = np.sqrt(walkFall[i][\"AccelerationX\"]**2 * \n",
    "                                                      walkFall[i][\"AccelerationY\"]**2 *\n",
    "                                                      walkFall[i][\"AccelerationZ\"]**2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_passed_runFall = []\n",
    "for i in range(3):\n",
    "    low_passed_runFallX = list(signal.filtfilt(b, a, runFall[i][\"AccelerationX\"]))\n",
    "    low_passed_runFallY = list(signal.filtfilt(b, a, runFall[i][\"AccelerationY\"]))\n",
    "    low_passed_runFallZ = list(signal.filtfilt(b, a, runFall[i][\"AccelerationZ\"]))\n",
    "    low_passed_runFall.append((pd.DataFrame(list(zip(low_passed_runFallX, low_passed_runFallY, low_passed_runFallZ)),\n",
    "                                            columns=[\"AccelerationX\", \"AccelerationY\", \"AccelerationZ\"])))\n",
    "for i in range(3):\n",
    "    low_passed_runFall[i][\"AccelerationT\"] = np.sqrt(runFall[i][\"AccelerationX\"]**2 * \n",
    "                                                      runFall[i][\"AccelerationY\"]**2 *\n",
    "                                                      runFall[i][\"AccelerationZ\"]**2 )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_passed_downSit = []\n",
    "for i in range(3):\n",
    "    low_passed_downSitX = list(signal.filtfilt(b, a, downSit[i][\"AccelerationX\"]))\n",
    "    low_passed_downSitY = list(signal.filtfilt(b, a, downSit[i][\"AccelerationY\"]))\n",
    "    low_passed_downSitZ = list(signal.filtfilt(b, a, downSit[i][\"AccelerationZ\"]))\n",
    "    low_passed_downSit.append((pd.DataFrame(list(zip(low_passed_downSitX, low_passed_downSitY, low_passed_downSitZ)),\n",
    "                                            columns=[\"AccelerationX\", \"AccelerationY\", \"AccelerationZ\"])))\n",
    "for i in range(3):\n",
    "    low_passed_downSit[i][\"AccelerationT\"] = np.sqrt(downSit[i][\"AccelerationX\"]**2 * \n",
    "                                                      downSit[i][\"AccelerationY\"]**2 *\n",
    "                                                      downSit[i][\"AccelerationZ\"]**2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_passed_freeFall = []\n",
    "for i in range(3):\n",
    "    low_passed_freeFallX = list(signal.filtfilt(b, a, freeFall[i][\"AccelerationX\"]))\n",
    "    low_passed_freeFallY = list(signal.filtfilt(b, a, freeFall[i][\"AccelerationY\"]))\n",
    "    low_passed_freeFallZ = list(signal.filtfilt(b, a, freeFall[i][\"AccelerationZ\"]))\n",
    "    low_passed_freeFall.append((pd.DataFrame(list(zip(low_passed_freeFallX, low_passed_freeFallY, low_passed_freeFallZ)),\n",
    "                                            columns=[\"AccelerationX\", \"AccelerationY\", \"AccelerationZ\"])))\n",
    "for i in range(3):\n",
    "    low_passed_freeFall[i][\"AccelerationT\"] = np.sqrt(freeFall[i][\"AccelerationX\"]**2 * \n",
    "                                                      freeFall[i][\"AccelerationY\"]**2 * freeFall[i][\"AccelerationZ\"]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `3. Transformation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_generator(df):\n",
    "    # total max Acceleration\n",
    "    max_AT = df['AccelerationT'].idxmax()\n",
    "    \n",
    "    # 1 sec before and after drop data\n",
    "    Imp_Data = df[max_AT - 50:max_AT + 25] \n",
    "    Imp_Data = pd.DataFrame(Imp_Data)\n",
    "    \n",
    "    MeanX = Imp_Data['AccelerationX'].mean()\n",
    "    MeanY = Imp_Data['AccelerationY'].mean()\n",
    "    MeanZ = Imp_Data['AccelerationZ'].mean()\n",
    "    MeanT = Imp_Data['AccelerationT'].mean()\n",
    "    \n",
    "    StdX = Imp_Data['AccelerationX'].std()\n",
    "    StdY = Imp_Data['AccelerationY'].std()\n",
    "    StdZ = Imp_Data['AccelerationZ'].std()\n",
    "    StdT = Imp_Data['AccelerationT'].std()\n",
    "    \n",
    "    MinX = Imp_Data['AccelerationX'].min()\n",
    "    MinY = Imp_Data['AccelerationY'].min()\n",
    "    MinZ = Imp_Data['AccelerationZ'].min()\n",
    "    MinT = Imp_Data['AccelerationT'].min()\n",
    "    \n",
    "    MaxX = Imp_Data['AccelerationX'].max()\n",
    "    MaxY = Imp_Data['AccelerationY'].max()\n",
    "    MaxZ = Imp_Data['AccelerationZ'].max()\n",
    "    MaxT = Imp_Data['AccelerationT'].max()\n",
    "    \n",
    "    stat = [{'MeanX':MeanX, 'MeanY':MeanY, 'MeanZ':MeanZ, 'MeanT':MeanT, \n",
    "             'StdX': StdX, 'StdY': StdY, 'StdZ': StdZ, 'StdT': StdT,\n",
    "             'MinX': MinX, 'MinY': MinY, 'MinZ': MinZ, 'MinT': MinT,\n",
    "             'MaxX':MaxX, 'MaxY':MaxY, 'MaxZ':MaxZ, 'MaxT':MaxT}]\n",
    "    \n",
    "    return pd.DataFrame(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_walkSit = stats_generator(low_passed_walkSit[0])\n",
    "for i in range(2):\n",
    "    stat_walkSit = stat_walkSit.append(stats_generator(low_passed_walkSit[i + 1]))\n",
    "stat_walkSit = stat_walkSit.dropna()\n",
    "stat_walkSit = stat_walkSit.reset_index(drop=True)\n",
    "stat_walkSit ['Fall'] = 0\n",
    "# fall 0 mean false i.e. no fall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_walkFall = stats_generator(low_passed_walkFall[0])\n",
    "for i in range(2):\n",
    "    stat_walkFall = stat_walkFall.append(stats_generator(low_passed_walkFall[i + 1]))\n",
    "stat_walkFall = stat_walkFall.dropna()\n",
    "stat_walkFall = stat_walkFall.reset_index(drop=True)\n",
    "stat_walkFall ['Fall'] = 1\n",
    "# fall 0 mean false i.e. no fall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_runFall = stats_generator(low_passed_runFall[0])\n",
    "for i in range(2):\n",
    "    stat_runFall = stat_runFall.append(stats_generator(low_passed_runFall[i + 1]))\n",
    "stat_runFall = stat_walkFall.dropna()\n",
    "stat_runFall = stat_walkFall.reset_index(drop=True)\n",
    "stat_runFall ['Fall'] = 1\n",
    "# fall 0 mean false i.e. no fall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MeanX</th>\n",
       "      <th>MeanY</th>\n",
       "      <th>MeanZ</th>\n",
       "      <th>MeanT</th>\n",
       "      <th>StdX</th>\n",
       "      <th>StdY</th>\n",
       "      <th>StdZ</th>\n",
       "      <th>StdT</th>\n",
       "      <th>MinX</th>\n",
       "      <th>MinY</th>\n",
       "      <th>MinZ</th>\n",
       "      <th>MinT</th>\n",
       "      <th>MaxX</th>\n",
       "      <th>MaxY</th>\n",
       "      <th>MaxZ</th>\n",
       "      <th>MaxT</th>\n",
       "      <th>Fall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.542930</td>\n",
       "      <td>0.904579</td>\n",
       "      <td>-0.303651</td>\n",
       "      <td>0.467309</td>\n",
       "      <td>0.343317</td>\n",
       "      <td>0.481893</td>\n",
       "      <td>0.448516</td>\n",
       "      <td>0.896633</td>\n",
       "      <td>-1.301513</td>\n",
       "      <td>-0.419411</td>\n",
       "      <td>-1.211874</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.048762</td>\n",
       "      <td>1.726148</td>\n",
       "      <td>0.097651</td>\n",
       "      <td>4.896431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.531983</td>\n",
       "      <td>1.569879</td>\n",
       "      <td>-0.046293</td>\n",
       "      <td>2.520955</td>\n",
       "      <td>0.461949</td>\n",
       "      <td>0.398333</td>\n",
       "      <td>0.155055</td>\n",
       "      <td>7.833440</td>\n",
       "      <td>-1.230656</td>\n",
       "      <td>0.859806</td>\n",
       "      <td>-0.415732</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.264583</td>\n",
       "      <td>2.371279</td>\n",
       "      <td>0.158859</td>\n",
       "      <td>48.845084</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.579644</td>\n",
       "      <td>1.635359</td>\n",
       "      <td>-0.035430</td>\n",
       "      <td>1.029004</td>\n",
       "      <td>0.391223</td>\n",
       "      <td>0.407906</td>\n",
       "      <td>0.129970</td>\n",
       "      <td>2.034076</td>\n",
       "      <td>-1.208973</td>\n",
       "      <td>0.865597</td>\n",
       "      <td>-0.328769</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>0.180888</td>\n",
       "      <td>2.343828</td>\n",
       "      <td>0.157854</td>\n",
       "      <td>10.453938</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MeanX     MeanY     MeanZ     MeanT      StdX      StdY      StdZ  \\\n",
       "0 -0.542930  0.904579 -0.303651  0.467309  0.343317  0.481893  0.448516   \n",
       "1 -0.531983  1.569879 -0.046293  2.520955  0.461949  0.398333  0.155055   \n",
       "2 -0.579644  1.635359 -0.035430  1.029004  0.391223  0.407906  0.129970   \n",
       "\n",
       "       StdT      MinX      MinY      MinZ      MinT      MaxX      MaxY  \\\n",
       "0  0.896633 -1.301513 -0.419411 -1.211874  0.000421  0.048762  1.726148   \n",
       "1  7.833440 -1.230656  0.859806 -0.415732  0.000082  0.264583  2.371279   \n",
       "2  2.034076 -1.208973  0.865597 -0.328769  0.001573  0.180888  2.343828   \n",
       "\n",
       "       MaxZ       MaxT  Fall  \n",
       "0  0.097651   4.896431     0  \n",
       "1  0.158859  48.845084     0  \n",
       "2  0.157854  10.453938     0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_downSit = stats_generator(low_passed_downSit[0])\n",
    "for i in range(2):\n",
    "    stat_downSit = stat_downSit.append(stats_generator(low_passed_downSit[i + 1]))\n",
    "stat_downSit = stat_downSit.dropna()\n",
    "stat_downSit = stat_downSit.reset_index(drop=True)\n",
    "stat_downSit ['Fall'] = 0\n",
    "stat_downSit\n",
    "# fall 0 mean false i.e. no fall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_freeFall = stats_generator(low_passed_freeFall[0])\n",
    "for i in range(2):\n",
    "    stat_freeFall = stat_freeFall.append(stats_generator(low_passed_freeFall[i + 1]))\n",
    "stat_freeFall = stat_freeFall.dropna()\n",
    "stat_freeFall = stat_freeFall.reset_index(drop=True)\n",
    "stat_freeFall ['Fall'] = 1\n",
    "# fall 1 mean false i.e. fall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `4. Importing the trained models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForestClf = pickle.load(open(\"Models/RandomForestClf.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaBoostclf = pickle.load(open(\"Models/AdaBoostClf.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MlpClf = pickle.load(open(\"Models/MlpClf.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. `Predicting`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walk and fall predictions: \n",
      "+---------------+----------+-----+\n",
      "| Random forest | AdaBoost | MLP |\n",
      "+---------------+----------+-----+\n",
      "|       1       |    1     |  0  |\n",
      "|       1       |    1     |  1  |\n",
      "|       1       |    1     |  1  |\n",
      "+---------------+----------+-----+\n"
     ]
    }
   ],
   "source": [
    "# 1. walkfall \n",
    "X = stat_walkFall.drop(\"Fall\", axis = 1)\n",
    "rfResults = randomForestClf.predict(X)\n",
    "adaResults = adaBoostclf.predict(X)\n",
    "mlpResults = MlpClf.predict(X)\n",
    "wfResults = pd.DataFrame()\n",
    "wfResults['Random forest'] = rfResults\n",
    "wfResults['AdaBoost'] = adaResults\n",
    "wfResults['MLP'] = mlpResults\n",
    "print(\"Walk and fall predictions: \")\n",
    "print(tabulate(wfResults, headers='keys', tablefmt=\"pretty\", showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walk and sit predictions: \n",
      "+---------------+----------+-----+\n",
      "| Random forest | AdaBoost | MLP |\n",
      "+---------------+----------+-----+\n",
      "|       0       |    0     |  0  |\n",
      "|       0       |    0     |  0  |\n",
      "|       0       |    0     |  0  |\n",
      "+---------------+----------+-----+\n"
     ]
    }
   ],
   "source": [
    "# 2. walksit \n",
    "X = stat_walkSit.drop(\"Fall\", axis = 1)\n",
    "rfResults = randomForestClf.predict(X)\n",
    "adaResults = adaBoostclf.predict(X)\n",
    "mlpResults = MlpClf.predict(X)\n",
    "wsResults = pd.DataFrame()\n",
    "wsResults['Random forest'] = rfResults\n",
    "wsResults['AdaBoost'] = adaResults\n",
    "wsResults['MLP'] = mlpResults\n",
    "print(\"Walk and sit predictions: \")\n",
    "print(tabulate(wsResults, headers='keys', tablefmt=\"pretty\", showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downstairs and sit predictions: \n",
      "+---------------+----------+-----+\n",
      "| Random forest | AdaBoost | MLP |\n",
      "+---------------+----------+-----+\n",
      "|       1       |    1     |  0  |\n",
      "|       1       |    1     |  0  |\n",
      "|       1       |    1     |  0  |\n",
      "+---------------+----------+-----+\n"
     ]
    }
   ],
   "source": [
    "# 4. down Sit \n",
    "X = stat_downSit.drop(\"Fall\", axis = 1)\n",
    "rfResults = randomForestClf.predict(X)\n",
    "adaResults = adaBoostclf.predict(X)\n",
    "mlpResults = MlpClf.predict(X)\n",
    "wsResults = pd.DataFrame()\n",
    "wsResults['Random forest'] = rfResults\n",
    "wsResults['AdaBoost'] = adaResults\n",
    "wsResults['MLP'] = mlpResults\n",
    "print(\"Downstairs and sit predictions: \")\n",
    "print(tabulate(wsResults, headers='keys', tablefmt=\"pretty\", showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run and fall predictions: \n",
      "+---------------+----------+-----+\n",
      "| Random forest | AdaBoost | MLP |\n",
      "+---------------+----------+-----+\n",
      "|       1       |    1     |  0  |\n",
      "|       1       |    1     |  1  |\n",
      "|       1       |    1     |  1  |\n",
      "+---------------+----------+-----+\n"
     ]
    }
   ],
   "source": [
    "# 4. stat_runFall \n",
    "X = stat_runFall.drop(\"Fall\", axis = 1)\n",
    "rfResults = randomForestClf.predict(X)\n",
    "adaResults = adaBoostclf.predict(X)\n",
    "mlpResults = MlpClf.predict(X)\n",
    "wsResults = pd.DataFrame()\n",
    "wsResults['Random forest'] = rfResults\n",
    "wsResults['AdaBoost'] = adaResults\n",
    "wsResults['MLP'] = mlpResults\n",
    "print(\"Run and fall predictions: \")\n",
    "print(tabulate(wsResults, headers='keys', tablefmt=\"pretty\", showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freefall predictions: \n",
      "+---------------+----------+-----+\n",
      "| Random forest | AdaBoost | MLP |\n",
      "+---------------+----------+-----+\n",
      "|       1       |    1     |  1  |\n",
      "|       1       |    1     |  1  |\n",
      "|       1       |    1     |  1  |\n",
      "+---------------+----------+-----+\n"
     ]
    }
   ],
   "source": [
    "# 5. walksit \n",
    "X = stat_freeFall.drop(\"Fall\", axis = 1)\n",
    "rfResults = randomForestClf.predict(X)\n",
    "adaResults = adaBoostclf.predict(X)\n",
    "mlpResults = MlpClf.predict(X)\n",
    "wsResults = pd.DataFrame()\n",
    "wsResults['Random forest'] = rfResults\n",
    "wsResults['AdaBoost'] = adaResults\n",
    "wsResults['MLP'] = mlpResults\n",
    "print(\"Freefall predictions: \")\n",
    "print(tabulate(wsResults, headers='keys', tablefmt=\"pretty\", showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring downsit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pridicted probability by Random forest : \n",
      "+----------+------+\n",
      "| Not-Fall | Fall |\n",
      "+----------+------+\n",
      "|   0.17   | 0.83 |\n",
      "|   0.27   | 0.73 |\n",
      "|   0.33   | 0.67 |\n",
      "+----------+------+\n",
      "Pridicted probability by Ada Boost : \n",
      "+----------------------+--------------------+\n",
      "|       Not-Fall       |        Fall        |\n",
      "+----------------------+--------------------+\n",
      "| 0.055932664219750385 | 0.9440673357802496 |\n",
      "| 0.32183885942881235  | 0.6781611405711877 |\n",
      "| 0.32183885942881235  | 0.6781611405711877 |\n",
      "+----------------------+--------------------+\n",
      "Pridicted probability by MLP : \n",
      "+--------------------+------------------------+\n",
      "|      Not-Fall      |          Fall          |\n",
      "+--------------------+------------------------+\n",
      "| 0.9999986863898758 | 1.3136101242371043e-06 |\n",
      "| 0.999017144449047  |  0.00098285555095297   |\n",
      "| 0.9999986549742913 |  1.34502570874002e-06  |\n",
      "+--------------------+------------------------+\n"
     ]
    }
   ],
   "source": [
    "# 4. down Sit \n",
    "X = stat_downSit.drop(\"Fall\", axis = 1)\n",
    "rfResults = randomForestClf.predict_proba(X)\n",
    "adaResults = adaBoostclf.predict_proba(X)\n",
    "mlpResults = MlpClf.predict_proba(X)\n",
    "\n",
    "pd.set_option('precision', 0)\n",
    "pd.set_option('display.float_format', lambda x: '%.0f' % x)\n",
    "\n",
    "\n",
    "rfResultsProba = pd.DataFrame()\n",
    "rfResultsProba[\"Not-Fall\"] = rfResults[:,0]\n",
    "rfResultsProba[\"Fall\"] = rfResults[:,1]\n",
    "print(\"Pridicted probability by Random forest : \")\n",
    "print(tabulate(rfResultsProba, headers='keys', tablefmt=\"pretty\", showindex=False))\n",
    "\n",
    "rfResultsProba = pd.DataFrame()\n",
    "rfResultsProba[\"Not-Fall\"] = adaResults[:,0]\n",
    "rfResultsProba[\"Fall\"] = adaResults[:,1]\n",
    "print(\"Pridicted probability by Ada Boost : \")\n",
    "print(tabulate(rfResultsProba, headers='keys', tablefmt=\"pretty\", showindex=False))\n",
    "\n",
    "rfResultsProba = pd.DataFrame()\n",
    "\n",
    "rfResultsProba[\"Not-Fall\"] = mlpResults[:,0]\n",
    "rfResultsProba[\"Fall\"] = mlpResults[:,1]\n",
    "print(\"Pridicted probability by MLP : \")\n",
    "print(tabulate(rfResultsProba, headers='keys', tablefmt=\"pretty\", showindex=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
